{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from house_project.Config.config_entity import DataTransfomationConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from house_project import logging\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder,OrdinalEncoder,PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from house_project.Utility.common import *\n",
    "from house_project.Utility.feature_engineering import FeatureEngineering\n",
    "import os \n",
    "from pathlib import Path\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransfomation:\n",
    "    def __init__(self):\n",
    "        self.data_transform = DataTransfomationConfig()\n",
    "        self.schema = Read_Yaml(\"End_to_End_House_Price_Estimater_IkmanData/schema.yaml\")\n",
    "        self.data_clean = FeatureEngineering()\n",
    "        \n",
    "        Create_Dir(self.data_transform.root_dir)\n",
    "            \n",
    "    def preprocess_step(self):\n",
    "        \n",
    "        num_columns = self.schema.get('scaler',[])\n",
    "        cat_columns = self.schema.get('one_hot',[])\n",
    "        power_col = self.schema.get('power',[])\n",
    "        \n",
    "        num_pipleine = Pipeline([\n",
    "            ('scaler',StandardScaler())\n",
    "        ])    \n",
    "        \n",
    "        cat_pipeline = Pipeline([\n",
    "            ('one_hot',OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "        \n",
    "        power_pipleine=Pipeline([\n",
    "            ('power',PowerTransformer(method='yeo-johnson'))\n",
    "        ])\n",
    "        \n",
    "        preprocess = ColumnTransformer([\n",
    "            ('power_pipleine',power_pipleine,power_col),\n",
    "            ('num_pipeline',num_pipleine,num_columns),\n",
    "            ('cat_pipeline',cat_pipeline,cat_columns)\n",
    "            \n",
    "        ])\n",
    "        return preprocess\n",
    "    def apply_feature_engineering_and_data_transfomation(self):\n",
    "        try:\n",
    "            #csv_file = check_csv_occur('End_to_End_House_Price_Estimater_IkmanData/artifacts/data_ingestion')\n",
    "            \n",
    "            data = pd.read_csv(Path(\"End_to_End_House_Price_Estimater_IkmanData/artifacts/data_ingestion/house_prices.csv\"))\n",
    "            \n",
    "            drop_columns = self.schema.get(\"drop_columns\",[])\n",
    "            \n",
    "            data = data.drop(columns=drop_columns,axis=1)\n",
    "            \n",
    "            \n",
    "            data = self.data_clean.clean_bath(data)\n",
    "            data = self.data_clean.clean_bed(data)\n",
    "            data = self.data_clean.clean_land_size(data)\n",
    "            data = self.data_clean.clean_house_size(data)\n",
    "            data = self.data_clean.clean_price(data)\n",
    "            data = self.data_clean.Geo_Address(data)\n",
    "            logging.info(\"data cleaning Completed \")\n",
    "            \n",
    "            outlier_columns = self.schema.get('outlier',[])\n",
    "            data = self.data_clean.remove_outliers_iqr(data=data,columns=outlier_columns)\n",
    "            logging.info('Outlier removel Completed')\n",
    "            logging.info(f\"Shape after outlier: {data.shape}\")\n",
    "            preprocess_obj = self.preprocess_step()\n",
    "            train_data,test_data = train_test_split(data,test_size=0.2,random_state=42)\n",
    "            target_col = self.schema.get('TARGET',[])\n",
    "            print(train_data.shape)\n",
    "            print(test_data.shape)\n",
    "            train_data_input_feature = train_data.drop(columns = target_col,axis = 1)\n",
    "            train_data_target_feature = train_data[target_col]\n",
    "            \n",
    "            test_data_input_feature = test_data.drop(columns = target_col,axis = 1)\n",
    "            test_data_target_feature = test_data[target_col]\n",
    "            \n",
    "            train_pre = preprocess_obj.fit_transform(train_data_input_feature)\n",
    "            test_pre = preprocess_obj.transform(test_data_input_feature)\n",
    "            print(train_pre.shape)\n",
    "            print(test_pre.shape)\n",
    "            \n",
    "            #train_data_target_feature = np.array(train_data_target_feature).reshape(-1, 1)\n",
    "            #test_data_target_feature = np.array(test_data_target_feature).reshape(-1, 1)\n",
    "\n",
    "            print(f\"train_pre shape: {train_pre.shape}\")\n",
    "            print(f\"train_data_target_feature shape: {train_data_target_feature.shape}\")\n",
    "\n",
    "            train_arr = np.hstack([train_pre, train_data_target_feature])\n",
    "            test_arr = np.hstack([test_pre, test_data_target_feature])\n",
    "\n",
    "            \n",
    "            \n",
    "            return data\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in data cleaning {e}\")\n",
    "            raise e    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2025-02-18 17:11:57,120 ] 20 root - INFO - Read the End_to_End_House_Price_Estimater_IkmanData/schema.yaml Yaml file\n",
      "[ 2025-02-18 17:11:57,123 ] 11 root - INFO - artifacts/data_transfomation Created Succesfully\n",
      "[ 2025-02-18 17:11:57,417 ] 39 root - INFO - Shape before dropna: (15327, 6)\n",
      "[ 2025-02-18 17:11:57,417 ] 42 root - INFO - Shape after dropna: (15291, 6)\n",
      "[ 2025-02-18 17:11:57,478 ] 51 root - INFO - data cleaning Completed \n",
      "[ 2025-02-18 17:11:57,478 ] 71 root - INFO - Remove the outliers from ['Baths', 'Land size', 'House size', 'Price', 'Beds']\n",
      "[ 2025-02-18 17:11:57,478 ] 71 root - INFO - Remove the outliers from ['Baths', 'Land size', 'House size', 'Price', 'Beds']\n",
      "[ 2025-02-18 17:11:57,478 ] 71 root - INFO - Remove the outliers from ['Baths', 'Land size', 'House size', 'Price', 'Beds']\n",
      "[ 2025-02-18 17:11:57,478 ] 71 root - INFO - Remove the outliers from ['Baths', 'Land size', 'House size', 'Price', 'Beds']\n",
      "[ 2025-02-18 17:11:57,495 ] 71 root - INFO - Remove the outliers from ['Baths', 'Land size', 'House size', 'Price', 'Beds']\n",
      "[ 2025-02-18 17:11:57,495 ] 55 root - INFO - Outlier removel Completed\n",
      "[ 2025-02-18 17:11:57,495 ] 56 root - INFO - Shape after outlier: (11985, 6)\n",
      "[ 2025-02-18 17:11:57,528 ] 86 root - ERROR - Error in data cleaning all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9588, 6)\n",
      "(2397, 6)\n",
      "(9588, 121)\n",
      "(2397, 121)\n",
      "train_pre shape: (9588, 121)\n",
      "train_data_target_feature shape: (9588, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[151], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m data_transfomation \u001b[38;5;241m=\u001b[39m DataTransfomation()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdata_transfomation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_feature_engineering_and_data_transfomation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[150], line 87\u001b[0m, in \u001b[0;36mDataTransfomation.apply_feature_engineering_and_data_transfomation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     86\u001b[0m     logging\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in data cleaning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[150], line 79\u001b[0m, in \u001b[0;36mDataTransfomation.apply_feature_engineering_and_data_transfomation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_pre shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_pre\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_data_target_feature shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_data_target_feature\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 79\u001b[0m train_arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_pre\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_target_feature\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m test_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([test_pre, test_data_target_feature])\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32md:\\anaconda\\envs\\house_pro\\lib\\site-packages\\numpy\\core\\shape_base.py:357\u001b[0m, in \u001b[0;36mhstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;66;03m# As a special case, dimension 0 of 1-dimensional arrays is \"horizontal\"\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arrs \u001b[38;5;129;01mand\u001b[39;00m arrs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, casting\u001b[38;5;241m=\u001b[39mcasting)\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "data_transfomation = DataTransfomation()\n",
    "data_transfomation.apply_feature_engineering_and_data_transfomation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "house_pro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
